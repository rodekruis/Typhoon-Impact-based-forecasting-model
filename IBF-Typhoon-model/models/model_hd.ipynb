{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to obtain model performance\n",
    "\n",
    "In this notebook, all the different models are trained and tested to obtain optimal selected features, hyperparameters and performance scores. The models to obtain the selected features and performance estimate are called from separate scripts. For all models, Recursive Feature Elimination with Cross Validation (to find the optimal number of features) is applied on the full dataset. With the selected features, the performance is estimated (using Nested CV). In addition to comparing the performance scores of the models trained, the scores are also compared to a benchmark model.\n",
    "\n",
    "This notebook consists of three main sections:\n",
    "\n",
    "\n",
    "\n",
    "Binary Classification <br>\n",
    "The models to perform a binary classification with threshold of 30% damage are trained and tested. \n",
    "\n",
    "Multiclass Classification <br>\n",
    "The models to perform multiclass classification with three classes are trained and tests.\n",
    "- 0 - 30%\n",
    "- 30% - 80%\n",
    "- 80% - 100%\n",
    "\n",
    "Regression <br>\n",
    "The models to obtain a continous prediction are trained and tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "from sklearn.feature_selection import RFECV\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    ")\n",
    "from sklearn.metrics import f1_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from numpy.lib.function_base import average\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    make_scorer,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import importlib\n",
    "import os\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    RFE,\n",
    "    mutual_info_regression,\n",
    "    f_regression,\n",
    "    mutual_info_classif,\n",
    ")\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import pickle\n",
    "import openpyxl\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path to the initial folder\n",
    "os.chdir(\"C:\\\\Users\\\\ATeklesadik\\\\OneDrive - Rode Kruis\\\\Documents\\\\documents\\\\Typhoon_IBF_Rice_Damage_Model\")\n",
    "#os.chdir(\"C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\")\n",
    "cdir = os.getcwd()\n",
    "import importlib\n",
    "\n",
    "# Binary classification functions\n",
    "from IBF_typhoon_model.models.binary_classification.xgb_binary import (\n",
    "    xgb_binary_features,\n",
    "    xgb_binary_performance,\n",
    ")\n",
    "from IBF_typhoon_model.models.binary_classification.rf_binary import (\n",
    "    rf_binary_features,\n",
    "    rf_binary_performance,\n",
    ")\n",
    "\n",
    "# Multiclass classification functions\n",
    "from IBF_typhoon_model.models.multiclass_classification.rf_multi import (\n",
    "    rf_multi_features,\n",
    "    rf_multi_performance,\n",
    ")\n",
    "from IBF_typhoon_model.models.multiclass_classification.xgb_multi import (\n",
    "    xgb_multi_features,\n",
    "    xgb_multi_performance,\n",
    ")\n",
    "\n",
    "# Regression functions\n",
    "from IBF_typhoon_model.models.regression.rf_regression import (\n",
    "    rf_regression_features,\n",
    "    rf_regression_performance,\n",
    ")\n",
    "from IBF_typhoon_model.models.regression.xgb_regression import (\n",
    "    xgb_regression_features,\n",
    "    xgb_regression_performance,\n",
    ")\n",
    "\n",
    "# Utility functions\n",
    "from IBF_typhoon_model.models.utility_functions.splitting_train_test import (\n",
    "    splitting_train_test,\n",
    ")\n",
    "from IBF_typhoon_model.models.utility_functions.determine_class import determine_class\n",
    "from IBF_typhoon_model.models.utility_functions.unweighted_random import (\n",
    "    unweighted_random,\n",
    ")\n",
    "from IBF_typhoon_model.models.utility_functions.weighted_random import weighted_random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_variable = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data\\\\geo_variable.csv\"))\n",
    "\n",
    "#past_typhoon_wind = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data\\\\historical_typhoon_wind\\\\historical_typhoons_wind_v2.csv\"))\n",
    "past_typhoon_wind = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data\\\\historical_typhoon_wind\\\\windfield.csv\"))\n",
    "past_typhoon_rain1 = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data\\\\historical_typhoon_wind\\\\PHL_admin3_zonal_statistics_2021_05_13.csv\"))\n",
    "past_typhoon_rain2 = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data\\\\all_rainfall.csv\"))\n",
    "\n",
    "material_variable2 = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data\\\\material_variable2.csv\"))\n",
    "data_matrix_new_variables = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data\\\\data_matrix_new_variables.csv\"))\n",
    "geo_variable = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data\\\\geo_variable.csv\"))\n",
    "grid_points_adm3 = pd.read_csv(os.path.join(cdir, \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\data-raw\\\\grid_points_admin3_v2.csv\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adm3_pcode</th>\n",
       "      <th>storm_id</th>\n",
       "      <th>value_count</th>\n",
       "      <th>v_max</th>\n",
       "      <th>name</th>\n",
       "      <th>dis_track_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>2008169N08135</td>\n",
       "      <td>11</td>\n",
       "      <td>10.247917</td>\n",
       "      <td>FENGSHEN</td>\n",
       "      <td>281.523886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>2011266N13139</td>\n",
       "      <td>179</td>\n",
       "      <td>26.144432</td>\n",
       "      <td>NESAT</td>\n",
       "      <td>196.819495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>2012331N03157</td>\n",
       "      <td>158</td>\n",
       "      <td>17.536221</td>\n",
       "      <td>BOPHA</td>\n",
       "      <td>156.977693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>2013220N12137</td>\n",
       "      <td>133</td>\n",
       "      <td>16.053228</td>\n",
       "      <td>UTOR</td>\n",
       "      <td>205.048564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PH012801000</td>\n",
       "      <td>2013301N13142</td>\n",
       "      <td>259</td>\n",
       "      <td>50.477992</td>\n",
       "      <td>KROSA</td>\n",
       "      <td>3.419138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    adm3_pcode       storm_id  value_count      v_max      name  dis_track_min\n",
       "0  PH012801000  2008169N08135           11  10.247917  FENGSHEN     281.523886\n",
       "1  PH012801000  2011266N13139          179  26.144432     NESAT     196.819495\n",
       "2  PH012801000  2012331N03157          158  17.536221     BOPHA     156.977693\n",
       "3  PH012801000  2013220N12137          133  16.053228      UTOR     205.048564\n",
       "4  PH012801000  2013301N13142          259  50.477992     KROSA       3.419138"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_typhoon_wind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ATeklesadik\\Miniconda3\\envs\\geo_env\\lib\\site-packages\\geopandas\\_vectorized.py:142: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'MultiPolygon'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  aout[:] = out\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "php_admin3 = gpd.read_file(os.path.join(cdir,'IBF_typhoon_model\\\\data\\\\restricted_data\\\\data-raw\\\\phl_admin3_simpl2.geojson'))\n",
    "php_admin1 = gpd.read_file(os.path.join(cdir,'IBF_typhoon_model\\\\data\\\\restricted_data\\\\data-raw\\\\phl_admin1_gadm_pcode.geojson'))\n",
    "php_admin_buffer = gpd.read_file(os.path.join(cdir,'IBF_typhoon_model\\\\data\\\\restricted_data\\\\data-raw\\\\phl_admin1_buffer.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "past_typhoon_wind <- read.csv(\"C_old/data/historical_typhoon_wind/windfield.csv\")%>%\n",
    "  dplyr::mutate(typhoon_name=toupper(paste0(name,substr(storm_id,1,4))),\n",
    "                Mun_Code=adm3_pcode)%>%dplyr::select(Mun_Code,typhoon_name,v_max,dis_track_min)\n",
    "             \n",
    "past_typhoon_rain1 <- read.csv(\"C:/Users/ATeklesadik/OneDrive - Rode Kruis/Documents/documents/Typhoon-Impact-based-forecasting-model_old/data/historical_typhoon_wind/PHL_admin3_zonal_statistics_2021_05_13.csv\") %>%\n",
    "  filter(typhoon_name %in% c('KAMMURI2019','PHANFONE2019','VONGFONG2020','MOLAVE2020','GONI2020')) %>% mutate(Mun_Code=pcode,typhoon=typhoon_name,ranfall=value)%>% dplyr::select(Mun_Code,typhoon,ranfall)\n",
    "past_typhoon_rain2 <- read.csv(\"C:/Users/ATeklesadik/OneDrive - Rode Kruis/Documents/documents/Typhoon-Impact-based-forecasting-model_old/data/all_rainfall.csv\") %>% mutate(ranfall=rainfll_max)%>% dplyr::select(Mun_Code,typhoon,ranfall)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "past_typhoon_rain<-bind_rows(past_typhoon_rain1,past_typhoon_rain2 )%>%dplyr::mutate(rainfll_max=ranfall,\n",
    "                                                                                     typhoon_name=toupper(typhoon))%>%dplyr::select(-typhoon)\n",
    "\n",
    "\n",
    "data_pre_disaster <- geo_variable%>%\n",
    "  left_join(material_variable2 %>% dplyr::select(-Region,-Province,-Municipality_City), by = \"Mun_Code\") %>%\n",
    "  left_join(data_matrix_new_variables , by = \"Mun_Code\") %>%\n",
    "  dplyr::mutate(coast_length= ifelse(is.na(coast_length),0, coast_length))\n",
    "\n",
    "\n",
    "\n",
    "impact <- read.csv(\"C:/Users/ATeklesadik/OneDrive - Rode Kruis/Documents/documents/Typhoon-Impact-based-forecasting-model_old/data/IMpact_data_philipines_final4.csv\")%>%\n",
    "  na.omit()%>%\n",
    "  dplyr::mutate(Mun_Code=pcode,typhoon_name=as.factor(toupper(paste0(typhoon,Year))))%>% dplyr::select(-pcode)#%>%na.omit()\n",
    "names(impact)<-c(\"id\",\"typhoon\", \"Year\",\"Totally\", \"Partially\",\"total\", \"Mun_Code\", \"typhoon_name\")\n",
    "\n",
    "\n",
    "data_pre_disaster%>%filter(Mun_Code=='PH020904000')%>%dplyr::select('Totally')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mun_code</th>\n",
       "      <th>typhoon</th>\n",
       "      <th>area_affected</th>\n",
       "      <th>storm_id</th>\n",
       "      <th>year</th>\n",
       "      <th>reg_code</th>\n",
       "      <th>prov_code</th>\n",
       "      <th>rice_area</th>\n",
       "      <th>perc_loss</th>\n",
       "      <th>mean_slope</th>\n",
       "      <th>...</th>\n",
       "      <th>glat</th>\n",
       "      <th>glon</th>\n",
       "      <th>coast_peri_ratio</th>\n",
       "      <th>rainfall_max_6h</th>\n",
       "      <th>rainfall_max_24h</th>\n",
       "      <th>vmax</th>\n",
       "      <th>dis_track_min</th>\n",
       "      <th>perc_loss_new</th>\n",
       "      <th>damage_above_30</th>\n",
       "      <th>class_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>goni2015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015226N12151</td>\n",
       "      <td>2015</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>124.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.35</td>\n",
       "      <td>...</td>\n",
       "      <td>7.475</td>\n",
       "      <td>124.58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.863333</td>\n",
       "      <td>2.347917</td>\n",
       "      <td>11.295801</td>\n",
       "      <td>271.221492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>mangkhut2018</td>\n",
       "      <td>104.31</td>\n",
       "      <td>2018250N12170</td>\n",
       "      <td>2018</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>236.24</td>\n",
       "      <td>0.441542</td>\n",
       "      <td>6.89</td>\n",
       "      <td>...</td>\n",
       "      <td>7.483</td>\n",
       "      <td>124.71</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.861667</td>\n",
       "      <td>2.931250</td>\n",
       "      <td>22.718248</td>\n",
       "      <td>111.246866</td>\n",
       "      <td>0.441542</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>molave2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020298N13131</td>\n",
       "      <td>2020</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>143.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>7.313</td>\n",
       "      <td>124.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.805833</td>\n",
       "      <td>2.076875</td>\n",
       "      <td>3.590794</td>\n",
       "      <td>400.835034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>usagi2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013259N17132</td>\n",
       "      <td>2013</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>126.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.21</td>\n",
       "      <td>...</td>\n",
       "      <td>6.710</td>\n",
       "      <td>124.46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.519167</td>\n",
       "      <td>1.859583</td>\n",
       "      <td>4.850429</td>\n",
       "      <td>389.636727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PH142708000</td>\n",
       "      <td>vamco2020</td>\n",
       "      <td>89.73</td>\n",
       "      <td>2020314N12131</td>\n",
       "      <td>2020</td>\n",
       "      <td>PH140000000</td>\n",
       "      <td>PH142700000</td>\n",
       "      <td>135.40</td>\n",
       "      <td>0.662703</td>\n",
       "      <td>13.79</td>\n",
       "      <td>...</td>\n",
       "      <td>5.785</td>\n",
       "      <td>125.34</td>\n",
       "      <td>0.458986</td>\n",
       "      <td>4.867500</td>\n",
       "      <td>2.057500</td>\n",
       "      <td>10.782503</td>\n",
       "      <td>199.648355</td>\n",
       "      <td>0.662703</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mun_code       typhoon  area_affected       storm_id  year     reg_code  \\\n",
       "0  PH142708000      goni2015           0.00  2015226N12151  2015  PH140000000   \n",
       "1  PH142708000  mangkhut2018         104.31  2018250N12170  2018  PH140000000   \n",
       "2  PH142708000    molave2020            NaN  2020298N13131  2020  PH140000000   \n",
       "3  PH142708000     usagi2013            NaN  2013259N17132  2013  PH140000000   \n",
       "4  PH142708000     vamco2020          89.73  2020314N12131  2020  PH140000000   \n",
       "\n",
       "     prov_code  rice_area  perc_loss  mean_slope  ...   glat    glon  \\\n",
       "0  PH142700000     124.72   0.000000       10.35  ...  7.475  124.58   \n",
       "1  PH142700000     236.24   0.441542        6.89  ...  7.483  124.71   \n",
       "2  PH142700000     143.32        NaN        5.48  ...  7.313  124.76   \n",
       "3  PH142700000     126.36        NaN        7.21  ...  6.710  124.46   \n",
       "4  PH142700000     135.40   0.662703       13.79  ...  5.785  125.34   \n",
       "\n",
       "   coast_peri_ratio  rainfall_max_6h  rainfall_max_24h       vmax  \\\n",
       "0          0.000000         2.863333          2.347917  11.295801   \n",
       "1          0.000000         5.861667          2.931250  22.718248   \n",
       "2          0.000000         6.805833          2.076875   3.590794   \n",
       "3          0.000000         3.519167          1.859583   4.850429   \n",
       "4          0.458986         4.867500          2.057500  10.782503   \n",
       "\n",
       "   dis_track_min  perc_loss_new  damage_above_30  class_old  \n",
       "0     271.221492       0.000000            False        0.0  \n",
       "1     111.246866       0.441542             True        1.0  \n",
       "2     400.835034            NaN            False        NaN  \n",
       "3     389.636727            NaN            False        NaN  \n",
       "4     199.648355       0.662703             True        1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagasa_name</th>\n",
       "      <th>unofficial_name</th>\n",
       "      <th>year</th>\n",
       "      <th>unofficial_name_year</th>\n",
       "      <th>name_year</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>landfall_date</th>\n",
       "      <th>landfall_time</th>\n",
       "      <th>storm_id</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aere</td>\n",
       "      <td>Bebeng</td>\n",
       "      <td>2011</td>\n",
       "      <td>Bebeng2011</td>\n",
       "      <td>aere2011</td>\n",
       "      <td>2011-05-05</td>\n",
       "      <td>2011-05-15</td>\n",
       "      <td>2011-05-07</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2011126N11129</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atsani</td>\n",
       "      <td>siony</td>\n",
       "      <td>2020</td>\n",
       "      <td>siony2020</td>\n",
       "      <td>atsani2020</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2020304N08148</td>\n",
       "      <td>no landfall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bopha</td>\n",
       "      <td>pablo</td>\n",
       "      <td>2012</td>\n",
       "      <td>pablo2012</td>\n",
       "      <td>bopha2012</td>\n",
       "      <td>2012-11-25</td>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>2012331N03157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>danas</td>\n",
       "      <td>falcon</td>\n",
       "      <td>2019</td>\n",
       "      <td>falcon2019</td>\n",
       "      <td>danas2019</td>\n",
       "      <td>2019-07-14</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2019195N13136</td>\n",
       "      <td>no landfall in PH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>durian</td>\n",
       "      <td>reming</td>\n",
       "      <td>2006</td>\n",
       "      <td>reming2006</td>\n",
       "      <td>durian2006</td>\n",
       "      <td>2006-11-24</td>\n",
       "      <td>2006-12-09</td>\n",
       "      <td>2006-11-30</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>2006329N06150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pagasa_name unofficial_name  year unofficial_name_year   name_year  \\\n",
       "0        aere          Bebeng  2011           Bebeng2011    aere2011   \n",
       "1      atsani           siony  2020            siony2020  atsani2020   \n",
       "2       bopha           pablo  2012            pablo2012   bopha2012   \n",
       "3       danas          falcon  2019           falcon2019   danas2019   \n",
       "4      durian          reming  2006           reming2006  durian2006   \n",
       "\n",
       "  start_date   end_date landfall_date landfall_time       storm_id  \\\n",
       "0 2011-05-05 2011-05-15    2011-05-07      21:00:00  2011126N11129   \n",
       "1 2020-10-29 2020-11-07    2020-11-06      00:00:00  2020304N08148   \n",
       "2 2012-11-25 2012-12-09    2012-12-03      21:00:00  2012331N03157   \n",
       "3 2019-07-14 2019-07-23    2019-07-17      00:00:00  2019195N13136   \n",
       "4 2006-11-24 2006-12-09    2006-11-30      06:00:00  2006329N06150   \n",
       "\n",
       "         Unnamed: 10  \n",
       "0                NaN  \n",
       "1        no landfall  \n",
       "2                NaN  \n",
       "3  no landfall in PH  \n",
       "4                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input data: the sheet that contains all the processed input data\n",
    "name = \"IBF_typhoon_model\\\\data\\\\restricted_data\\\\combined_input_data\\\\input_data_05.xlsx\"\n",
    "path = os.path.join(cdir, name)\n",
    "df = pd.read_excel(path, engine=\"openpyxl\")\n",
    "display(df.head(5))\n",
    "\n",
    "# Typhoon overview\n",
    "file_name = \"IBF_typhoon_model\\\\data\\\\data_overview.xlsx\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "df_typh_overview = pd.read_excel(path, sheet_name=\"typhoon_overview\", engine=\"openpyxl\")\n",
    "display(df_typh_overview.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the features to be used: should be available for historical and future typhoons\n",
    "features = [\n",
    "    \"mean_slope\",\n",
    "    \"mean_elevation_m\",\n",
    "    \"ruggedness_stdev\",\n",
    "    \"mean_ruggedness\",\n",
    "    \"slope_stdev\",\n",
    "    \"area_km2\",\n",
    "    \"poverty_perc\",\n",
    "    \"with_coast\",\n",
    "    \"coast_length\",\n",
    "    \"perimeter\",\n",
    "    \"glat\",\n",
    "    \"glon\",\n",
    "    \"coast_peri_ratio\",\n",
    "    \"rainfall_max_6h\",\n",
    "    \"rainfall_max_24h\",\n",
    "    \"dis_track_min\",\n",
    "    \"vmax\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification\n",
    "\n",
    "This section obtain the optimal Binary Classification models and the performance estimates, for a 30% threshold. Two models are implemented: Random Forest Classifier, XGBoost Classifier. First, the model is trained on the full dataset to obtain the optimal features followed by a model that obtains the performance estimate using Nested Cross Validation. \n",
    "\n",
    "- Performance Metric\n",
    "- Nested Cross Validation\n",
    "- Benchmark Models\n",
    "- Main findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the general input variables: for the dataframe with threshold 30\n",
    "# Contorplot threshold was used to create damage_above_30 variable\n",
    "df_binary = df[df['damage_above_30'].notnull()]\n",
    "df_binary[\"class_value_binary\"] = [\n",
    "    1 if df_binary[\"damage_above_30\"][i] == True else 0 for i in range(len(df_binary))\n",
    "]\n",
    "\n",
    "# Setting for feature selection on full data set\n",
    "X = df_binary[features]\n",
    "y = df_binary[\"class_value_binary\"]\n",
    "y = y.astype(int)\n",
    "\n",
    "# Setting the train and the test sets for obtaining performance estimate\n",
    "df_train_list, df_test_list = splitting_train_test(df_binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain features and optimal hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of selected features RF Binary: 3\n",
    "\n",
    "Selected features RF Binary:\n",
    "- rainfall_max_6h\n",
    "- dis_track_min\n",
    "- vmax\n",
    "\n",
    "\n",
    "Selected parameters RF Binary:\n",
    "- max_depth = 20\n",
    "- min_samples_leaf = 5\n",
    "- min_samples_split = 15\n",
    "- n_estimators = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random forest search grid\n",
    "rf_search_space = [\n",
    "    {\n",
    "        \"estimator__n_estimators\": [100, 250],\n",
    "        \"estimator__max_depth\": [20, None],\n",
    "        \"estimator__min_samples_split\": [2, 8, 10, 15],\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Obtaining the selected features based on the full dataset\n",
    "selected_features_rf_binary, selected_params_rf_binary_full = rf_binary_features(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    features=features,\n",
    "    search_space=rf_search_space,\n",
    "    cv_splits=5,\n",
    "    class_weight=\"balanced\",\n",
    "    min_features_to_select=1,\n",
    "    GS_score=\"f1\",\n",
    "    GS_randomized=False,\n",
    "    GS_n_iter=10,\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "print(f\"Number of selected features RF Binary: {len(selected_features_rf_binary)}\")\n",
    "print(f\"Selected features RF Binary: {selected_features_rf_binary}\")\n",
    "print(f\"Selected Parameters RF Binary {selected_params_rf_binary_full}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining performance estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the selected features for RF --> based on outcome in previous cell\n",
    "selected_features_rf_binary = [\n",
    "    \"rainfall_max_6h\",\n",
    "    \"dis_track_min\",\n",
    "    \"vmax\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random forest search grid\n",
    "rf_search_space = [\n",
    "    {\n",
    "        \"rf__n_estimators\": [100, 250],\n",
    "        \"rf__max_depth\": [20, None],\n",
    "        \"rf__min_samples_split\": [2, 8, 15],\n",
    "        \"rf__min_samples_leaf\": [1, 3, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Obtaining the performance estimate\n",
    "df_predicted_rf_binary, selected_params_rf_binary = rf_binary_performance(\n",
    "    df_train_list=df_train_list,\n",
    "    df_test_list=df_test_list,\n",
    "    features=selected_features_rf_binary,\n",
    "    search_space=rf_search_space,\n",
    "    stratK=True,\n",
    "    cv_splits=5,\n",
    "    class_weight=\"balanced\",\n",
    "    GS_score=\"f1\",\n",
    "    GS_randomized=False,\n",
    "    GS_n_iter=10,\n",
    "    verbose=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:3: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_binary.p'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_binary.p\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(selected_params_rf_binary, open(path, \"wb\"))\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_rf_binary.csv\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "df_predicted_rf_binary.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining optimal features and hyperparamters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of selected features XGGBoost Binary: 3\n",
    "\n",
    "Selected features XGBoost Binary:\n",
    "- rainfall_max_6h\n",
    "- dis_track_min\n",
    "- vmax\n",
    "\n",
    "Selected parameters XGBoost Binary:\n",
    "- reg_lambda = 1\n",
    "- n_estimators = 200\n",
    "- max_depth = 6\n",
    "- learning_rate = 0.1\n",
    "- gamma = 0.1\n",
    "- colsample_bytree = 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the XGBoost search grid for full dataset\n",
    "xgb_search_space = [\n",
    "    {\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\n",
    "        \"estimator__max_depth\": [6, 8],\n",
    "        \"estimator__reg_lambda\": [0.001, 0.1, 1],\n",
    "        \"estimator__n_estimators\": [100, 200],\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Obtaining the selected features based on the full dataset\n",
    "selected_features_xgb_binary, selected_params_xgb_binary_full = xgb_binary_features(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    features=features,\n",
    "    search_space=xgb_search_space,\n",
    "    objective=\"binary:hinge\",\n",
    "    cv_splits=5,\n",
    "    min_features_to_select=1,\n",
    "    GS_score=\"f1\",\n",
    "    GS_n_iter=50,\n",
    "    GS_randomized=True,\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "print(f\"Number of selected features XGBoost Binary {len(selected_features_xgb_binary)}\")\n",
    "print(f\"Selected features XGBoost Binary: {selected_features_xgb_binary}\")\n",
    "print(f\"Selected parameters XGBoost Binary: {selected_params_xgb_binary_full}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining performance estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the selected features for XGB --> based on outcome previous cell\n",
    "selected_features_xgb_binary = [\"rainfall_max_6h\", \"dis_track_min\", \"vmax\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the XGBoost search grid\n",
    "xgb_search_space = [\n",
    "    {\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\n",
    "        \"xgb__max_depth\": [6, 8],\n",
    "        \"xgb__reg_lambda\": [0.001, 0.1, 1],\n",
    "        \"xgb__n_estimators\": [100, 200],\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Obtaining the performance estimate\n",
    "df_predicted_xgb_binary, selected_params_xgb_binary = xgb_binary_performance(\n",
    "    df_train_list=df_train_list,\n",
    "    df_test_list=df_test_list,\n",
    "    features=selected_features_xgb_binary,\n",
    "    search_space=xgb_search_space,\n",
    "    stratK=True,\n",
    "    cv_splits=5,\n",
    "    objective=\"binary:hinge\",\n",
    "    GS_score=\"f1\",\n",
    "    GS_randomized=True,\n",
    "    GS_n_iter=50,\n",
    "    verbose=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:3: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_xgb_binary.p'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_xgb_binary.p\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(selected_params_xgb_binary, open(path, \"wb\"))\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_xgb_binary.csv\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "df_predicted_xgb_binary.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random unweighted predictions\n",
    "df_predicted_random = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\n",
    "\n",
    "for i in range(len(df_train_list)):\n",
    "\n",
    "    train = df_train_list[i]\n",
    "    test = df_test_list[i]\n",
    "\n",
    "    y_train = train[\"class_value_binary\"]\n",
    "    y_test = test[\"class_value_binary\"]\n",
    "\n",
    "    y_pred_test = unweighted_random(y_train, y_test)\n",
    "    df_predicted_temp = pd.DataFrame(\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\n",
    "    )\n",
    "\n",
    "    df_predicted_random = pd.concat([df_predicted_random, df_predicted_temp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Weighted Predictions\n",
    "df_predicted_random_weighted = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\n",
    "for i in range(len(df_train_list)):\n",
    "\n",
    "    train = df_train_list[i]\n",
    "    test = df_test_list[i]\n",
    "\n",
    "    y_train = train[\"class_value_binary\"]\n",
    "    y_test = test[\"class_value_binary\"]\n",
    "\n",
    "    y_pred_test = weighted_random(y_train, y_test)\n",
    "    df_predicted_temp = pd.DataFrame(\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\n",
    "    )\n",
    "\n",
    "    df_predicted_random_weighted = pd.concat(\n",
    "        [df_predicted_random_weighted, df_predicted_temp]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Fores</td>\n",
       "      <td>0.527349</td>\n",
       "      <td>0.535613</td>\n",
       "      <td>0.519337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.518862</td>\n",
       "      <td>0.558405</td>\n",
       "      <td>0.484549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random</td>\n",
       "      <td>0.377255</td>\n",
       "      <td>0.491453</td>\n",
       "      <td>0.306122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weighted Random</td>\n",
       "      <td>0.329497</td>\n",
       "      <td>0.387464</td>\n",
       "      <td>0.286617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Models  F1 score    Recall  Precision\n",
       "0     Random Fores  0.527349  0.535613   0.519337\n",
       "1          XGBoost  0.518862  0.558405   0.484549\n",
       "2           Random  0.377255  0.491453   0.306122\n",
       "3  Weighted Random  0.329497  0.387464   0.286617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Fores\": df_predicted_rf_binary,\n",
    "    \"XGBoost\": df_predicted_xgb_binary,\n",
    "    \"Random\": df_predicted_random,\n",
    "    \"Weighted Random\": df_predicted_random_weighted,\n",
    "}\n",
    "\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "# add 'list' if error\n",
    "for df_temp in models.values():\n",
    "    f1.append(f1_score(list(df_temp[\"actual\"]), list(df_temp[\"predicted\"])))\n",
    "    precision.append(precision_score(list(df_temp[\"actual\"]), list(df_temp[\"predicted\"])))\n",
    "    recall.append(recall_score(list(df_temp[\"actual\"]), list(df_temp[\"predicted\"])))\n",
    "\n",
    "df_results_binary = pd.DataFrame(\n",
    "    {\"Models\": list(models.keys()), \"F1 score\": f1, \"Recall\": recall, \"Precision\": precision}\n",
    ")\n",
    "\n",
    "display(df_results_binary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:20: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_binary_rf.sav'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "### Training the optimal model\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    n_estimators=250,\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=5,\n",
    "    min_samples_split=15,\n",
    ")\n",
    "\n",
    "selected_features_rf_binary = [\n",
    "    \"rainfall_max_6h\",\n",
    "    \"dis_track_min\",\n",
    "    \"vmax\",\n",
    "]\n",
    "\n",
    "rf_fitted = rf.fit(X[selected_features_rf_binary], y)\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_binary_rf.sav\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(rf_fitted, open(path, \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "This section obtains the optimal Multiclass Classification models and the performance estimates, with three classes. Two models are implemented: Random Forest Classifier, XGBoost Classifier. First, the model is trained on the full dataset to obtain the optimal features followed by a model that obtains the performance estimate using Nested Cross Validation. The classes are:\n",
    "- 0 - 30%\n",
    "- 30% - 80%\n",
    "- 80% - 100% <br> <br>\n",
    "\n",
    "\n",
    "- Performance Metric\n",
    "- Nested Cross Validation\n",
    "- Benchmark Models\n",
    "- Main findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Setting class value\n",
    "# Set final boundary slightly over 1 so 1's are included as well\n",
    "df_multi = df[df['perc_loss'].notnull()]\n",
    "classes = {\"0\": [0, 0.3], \"1\": [0.3, 0.8], \"2\": [0.8, 1.1]}\n",
    "df_multi[\"class_value_multi\"] = df_multi[\"perc_loss\"].apply(\n",
    "    lambda x: determine_class(x, classes=classes)\n",
    ")\n",
    "\n",
    "# Setting for feature seleciton on full data set\n",
    "X = df_multi[features]\n",
    "y = df_multi[\"class_value_multi\"]\n",
    "\n",
    "# Setting train and test set for obtaining performance estimate\n",
    "df_train_list, df_test_list = splitting_train_test(df_multi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the optimal hyperparameters and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of features selected in RF multiclass: 14\n",
    "\n",
    "The selected features ares:\n",
    "- mean_slope\n",
    "- mean_elevation_m\n",
    "- ruggedness_stdev\n",
    "- mean_ruggedness\n",
    "- slope_stdev\n",
    "- area_km2\n",
    "- poverty_perc\n",
    "- perimeter\n",
    "- glat\n",
    "- glon\n",
    "- rainfall_max_6h\n",
    "- rainfall_max_24h\n",
    "- dis_track_min\n",
    "- vmax\n",
    "\n",
    "Selected Parameters in RF multiclass: \n",
    "- max_depth = None\n",
    "- min_samples_leaf = 3\n",
    "- min_samples_split = 15\n",
    "- n_estimators = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random forest search grid\n",
    "rf_search_space = [\n",
    "    {\n",
    "        \"estimator__n_estimators\": [50, 100, 150],\n",
    "        \"estimator__max_depth\": [20, None],\n",
    "        \"estimator__min_samples_split\": [2, 10, 15],\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "selected_features_rf_multi, selected_params_rf_multi_full = rf_multi_features(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    features=features,\n",
    "    search_space=rf_search_space,\n",
    "    cv_splits=5,\n",
    "    class_weight=\"balanced\",\n",
    "    min_features_to_select=1,\n",
    "    GS_score=\"f1_macro\",\n",
    "    GS_randomized=False,\n",
    "    GS_n_iter=10,\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Number of features selected in RF multiclass: {len(selected_features_rf_multi)}\"\n",
    ")\n",
    "print(f\"Selected features RF multiclass: {selected_features_rf_multi}\")\n",
    "print(f\"Selected Parameters in RF multiclass: {selected_params_rf_multi_full}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the performance estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the selected features for RF --> based on output previous cell\n",
    "selected_features_rf_multi = [\n",
    "    \"mean_slope\",\n",
    "    \"mean_elevation_m\",\n",
    "    \"ruggedness_stdev\",\n",
    "    \"mean_ruggedness\",\n",
    "    \"slope_stdev\",\n",
    "    \"area_km2\",\n",
    "    \"poverty_perc\",\n",
    "    \"perimeter\",\n",
    "    \"glat\",\n",
    "    \"glon\",\n",
    "    \"rainfall_max_6h\",\n",
    "    \"rainfall_max_24h\",\n",
    "    \"dis_track_min\",\n",
    "    \"vmax\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the performance estimate\n",
    "rf_search_space = [\n",
    "    {\n",
    "        \"rf__n_estimators\": [50, 100, 150],\n",
    "        \"rf__max_depth\": [20, None],\n",
    "        \"rf__min_samples_split\": [2, 10, 15],\n",
    "        \"rf__min_samples_leaf\": [1, 3, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "df_predicted_rf_multi, selected_params_rf_multi = rf_multi_performance(\n",
    "    df_train_list=df_train_list,\n",
    "    df_test_list=df_test_list,\n",
    "    features=selected_features_rf_multi,\n",
    "    search_space=rf_search_space,\n",
    "    stratK=True,\n",
    "    cv_splits=5,\n",
    "    class_weight=\"balanced\",\n",
    "    GS_score=\"f1_macro\",\n",
    "    GS_randomized=False,\n",
    "    GS_n_iter=10,\n",
    "    verbose=10,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:4: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_multi.p'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "#Saving the results\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_multi.p\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(selected_params_rf_multi, open(path, \"wb\"))\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_rf_multi.csv\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "df_predicted_rf_multi.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the optimal features and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of selected features: 10\n",
    "\n",
    "Selected features:\n",
    "- mean_slope\n",
    "- mean_elevation_m\n",
    "- ruggedness_stdev\n",
    "- slope_stdev\n",
    "- coast_length\n",
    "- coast_peri_ratio\n",
    "- rainfall_max_6h\n",
    "- rainfall_max_24h\n",
    "- dis_track_min\n",
    "- vmax\n",
    "\n",
    "Selected hyperparameters:\n",
    "- reg_lambda = 1\n",
    "- n_estimators = 200\n",
    "- max_depth = 6\n",
    "- learning_rate = 0.5\n",
    "- gamma = 0.1\n",
    "- colsample_bytree = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting class value\n",
    "# Set final boundary slightly over 1 so 1's are included as well\n",
    "df_multi = df[df['perc_loss'].notnull()]\n",
    "classes = {0: [0, 0.3], 1: [0.3, 0.8], 2: [0.8, 1.1]}\n",
    "df_multi[\"class_value_multi\"] = df_multi[\"perc_loss\"].apply(\n",
    "    lambda x: determine_class(x, classes=classes)\n",
    ")\n",
    "\n",
    "# Setting for feature seleciton on full data set\n",
    "X = df_multi[features]\n",
    "y = df_multi[\"class_value_multi\"]\n",
    "\n",
    "# Setting train and test set for obtaining performance estimate\n",
    "df_train_list, df_test_list = splitting_train_test(df_multi)\n",
    "\n",
    "# Setting the XGBoost search grid\n",
    "xgb_search_space = [\n",
    "    {\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\n",
    "        \"estimator__max_depth\": [6, 8],\n",
    "        \"estimator__reg_lambda\": [0.001, 0.1, 1],\n",
    "        \"estimator__n_estimators\": [100, 200],\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7],\n",
    "    }\n",
    "]\n",
    "\n",
    "selected_features_xgb_multi, selected_params_xgb_multi_full = xgb_multi_features(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    features=features,\n",
    "    num_class=len(classes),\n",
    "    search_space=xgb_search_space,\n",
    "    objective=\"multi:softmax\",\n",
    "    cv_splits=5,\n",
    "    min_features_to_select=1,\n",
    "    GS_score=\"f1_macro\",\n",
    "    GS_randomized=True,\n",
    "    GS_n_iter=50,\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Number of features selected in RF multiclass: {len(selected_features_xgb_multi)}\"\n",
    ")\n",
    "print(f\"Selected features RF multiclass: {selected_features_xgb_multi}\")\n",
    "print(f\"Selected Parameters in RF multiclass: {selected_params_xgb_multi_full}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the selected features for XGB\n",
    "selected_features_xgb_multi = [\n",
    "    \"mean_slope\",\n",
    "    \"mean_elevation_m\",\n",
    "    \"ruggedness_stdev\",\n",
    "    \"slope_stdev\",\n",
    "    \"coast_length\",\n",
    "    \"coast_peri_ratio\",\n",
    "    \"rainfall_max_6h\",\n",
    "    \"rainfall_max_24h\",\n",
    "    \"dis_track_min\",\n",
    "    \"vmax\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the XGBoost search grid\n",
    "xgb_search_space = [\n",
    "    {\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\n",
    "        \"xgb__max_depth\": [6, 8],\n",
    "        \"xgb__reg_lambda\": [0.001, 0.1, 1],\n",
    "        \"xgb__n_estimators\": [100, 200],\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7],\n",
    "    }\n",
    "]\n",
    "\n",
    "df_predicted_xgb_multi, selected_params_xgb_multi = xgb_multi_performance(\n",
    "    df_train_list=df_train_list,\n",
    "    df_test_list=df_test_list,\n",
    "    num_class=len(classes),\n",
    "    features=selected_features_xgb_multi,\n",
    "    search_space=xgb_search_space,\n",
    "    stratK=True,\n",
    "    cv_splits=5,\n",
    "    objective=\"multi:softmax\",\n",
    "    GS_score=\"f1_macro\",\n",
    "    GS_randomized=True,\n",
    "    GS_n_iter=50,\n",
    "    verbose=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_xgb_multi.p\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(selected_params_xgb_multi, open(path, \"wb\"))\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_xgb_multi.csv\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "df_predicted_xgb_multi.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random unweighted predictions\n",
    "df_predicted_random_multi = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\n",
    "\n",
    "for i in range(len(df_train_list)):\n",
    "\n",
    "    train = df_train_list[i]\n",
    "    test = df_test_list[i]\n",
    "\n",
    "    y_train = train[\"class_value_multi\"]\n",
    "    y_test = test[\"class_value_multi\"]\n",
    "\n",
    "    y_pred_test = unweighted_random(y_train, y_test)\n",
    "    df_predicted_temp = pd.DataFrame(\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\n",
    "    )\n",
    "\n",
    "    df_predicted_random_multi = pd.concat(\n",
    "        [df_predicted_random_multi, df_predicted_temp]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Weighted Predictions\n",
    "df_predicted_random_weighted_multi = pd.DataFrame(\n",
    "    columns=[\"year\", \"actual\", \"predicted\"]\n",
    ")\n",
    "for i in range(len(df_train_list)):\n",
    "\n",
    "    train = df_train_list[i]\n",
    "    test = df_test_list[i]\n",
    "\n",
    "    y_train = train[\"class_value_multi\"]\n",
    "    y_test = test[\"class_value_multi\"]\n",
    "\n",
    "    y_pred_test = weighted_random(y_train, y_test)\n",
    "    df_predicted_temp = pd.DataFrame(\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\n",
    "    )\n",
    "\n",
    "    df_predicted_random_weighted_multi = pd.concat(\n",
    "        [df_predicted_random_weighted_multi, df_predicted_temp]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.409386</td>\n",
       "      <td>0.410419</td>\n",
       "      <td>0.409806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random</td>\n",
       "      <td>0.298415</td>\n",
       "      <td>0.330347</td>\n",
       "      <td>0.329676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weighted Random</td>\n",
       "      <td>0.335421</td>\n",
       "      <td>0.340306</td>\n",
       "      <td>0.339631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Models  F1 score    Recall  Precision\n",
       "0    Random Forest  0.409386  0.410419   0.409806\n",
       "1           Random  0.298415  0.330347   0.329676\n",
       "2  Weighted Random  0.335421  0.340306   0.339631"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": df_predicted_rf_multi,\n",
    "    # \"XGBoost\": df_predicted_xgb_multi,\n",
    "    \"Random\": df_predicted_random_multi,\n",
    "    \"Weighted Random\": df_predicted_random_weighted_multi,\n",
    "}\n",
    "\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "# add 'list' if error\n",
    "for df_temp in models.values():\n",
    "    f1.append(f1_score(df_temp[\"actual\"], df_temp[\"predicted\"], average=\"macro\"))\n",
    "    precision.append(precision_score(df_temp[\"actual\"], df_temp[\"predicted\"], average=\"macro\"))\n",
    "    recall.append(recall_score(df_temp[\"actual\"], df_temp[\"predicted\"], average=\"macro\"))\n",
    "\n",
    "df_results_multi = pd.DataFrame(\n",
    "    {\"Models\": list(models.keys()), \"F1 score\": f1, \"Recall\": recall, \"Precision\": precision}\n",
    ")\n",
    "\n",
    "display(df_results_multi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:31: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_multi_rf.sav'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "### Training the optimal model\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    n_estimators=50,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=3,\n",
    "    min_samples_split=15,\n",
    ")\n",
    "\n",
    "selected_features_rf_multi = [\n",
    "    \"mean_slope\",\n",
    "    \"mean_elevation_m\",\n",
    "    \"ruggedness_stdev\",\n",
    "    \"mean_ruggedness\",\n",
    "    \"slope_stdev\",\n",
    "    \"area_km2\",\n",
    "    \"poverty_perc\",\n",
    "    \"perimeter\",\n",
    "    \"glat\",\n",
    "    \"glon\",\n",
    "    \"rainfall_max_6h\",\n",
    "    \"rainfall_max_24h\",\n",
    "    \"dis_track_min\",\n",
    "    \"vmax\",\n",
    "]\n",
    "\n",
    "rf_fitted = rf.fit(X[selected_features_rf_multi], y)\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_multi_rf.sav\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(rf_fitted, open(path, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "This sections contains the Regression models that are trained and tested to obtain the optimal model, hyperparameter settings and features. First the model is trained on the full dataset to obtain the optimal features followed by a model that obtains the performance estimate using Nested Cross Validation.\n",
    "\n",
    "\n",
    "- Performance metrics\n",
    "- Nested Cross Validation\n",
    "- Benchmark Models\n",
    "- Main finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset for feature selection\n",
    "df_regr = df[df['perc_loss'].notnull()]\n",
    "\n",
    "X = df_regr[features]\n",
    "y = df_regr[\"perc_loss\"]\n",
    "\n",
    "# Setting the train and the test sets for obtaining performance estimate\n",
    "df_train_list, df_test_list = splitting_train_test(df_regr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the optimal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of selected features RF Regression: 12\n",
    "\n",
    "Selected features RF Regression:\n",
    "- mean_slope\n",
    "- mean_elevation_m\n",
    "- ruggedness_stdev\n",
    "- mean_ruggedness\n",
    "- area_km2\n",
    "- coast_length\n",
    "- poverty_perc\n",
    "- perimeter\n",
    "- glat\n",
    "- glon\n",
    "- coast_peri_ratio\n",
    "- rainfall_max_6h\n",
    "- rainfall_max_24h\n",
    "- dis_track_min\n",
    "- vmax\n",
    "\n",
    "\n",
    "Selected Parameters RF Regression: \n",
    "- max_depth = 20\n",
    "- min_samples_leaf = 1\n",
    "- min_samples_split = 8\n",
    "- n_estimators = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Setting input varialbes\n",
    "rf_search_space = [\n",
    "    {\n",
    "        \"estimator__n_estimators\": [100, 250],\n",
    "        \"estimator__max_depth\": [20, None],\n",
    "        \"estimator__min_samples_split\": [2, 8, 10],\n",
    "        \"estimator__min_samples_leaf\": [1, 3, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "(\n",
    "    selected_features_rf_regr,\n",
    "    selected_params_rf_regr_full,\n",
    ") = rf_regression_features(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    features=features,\n",
    "    search_space=rf_search_space,\n",
    "    min_features_to_select=1,\n",
    "    cv_splits=5,\n",
    "    GS_score=\"neg_root_mean_squared_error\",\n",
    "    GS_randomized=False,\n",
    "    GS_n_iter=10,\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Number of selected features RF Regression {len(selected_features_rf_regr)}\"\n",
    ")\n",
    "print(f\"Selected features RF Regression: {selected_features_rf_regr}\")\n",
    "print(f\"Selected Parameters RF Regression: {selected_params_rf_regr_full}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the performance estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on output previous cell\n",
    "selected_features_rf_regr = [\n",
    "    \"mean_slope\",\n",
    "    \"mean_elevation_m\",\n",
    "    \"ruggedness_stdev\",\n",
    "    \"mean_ruggedness\",\n",
    "    \"area_km2\",\n",
    "    \"coast_length\",\n",
    "    \"poverty_perc\",\n",
    "    \"perimeter\",\n",
    "    \"glat\",\n",
    "    \"glon\",\n",
    "    \"coast_peri_ratio\",\n",
    "    \"rainfall_max_6h\",\n",
    "    \"rainfall_max_24h\",\n",
    "    \"dis_track_min\",\n",
    "    \"vmax\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Setting input varialbes\n",
    "rf_search_space = [\n",
    "    {\n",
    "        \"rf__n_estimators\": [100, 250],\n",
    "        \"rf__max_depth\": [20, None],\n",
    "        \"rf__min_samples_split\": [2, 8, 10],\n",
    "        \"rf__min_samples_leaf\": [1, 3, 5],\n",
    "    }\n",
    "]\n",
    "\n",
    "df_predicted_rf_regr, selected_params_rf_regr = rf_regression_performance(\n",
    "    df_train_list=df_train_list,\n",
    "    df_test_list=df_test_list,\n",
    "    features=selected_features_rf_regr,\n",
    "    search_space=rf_search_space,\n",
    "    cv_splits=5,\n",
    "    GS_score=\"neg_root_mean_squared_error\",\n",
    "    GS_randomized=False,\n",
    "    GS_n_iter=10,\n",
    "    verbose=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:3: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_regr.p'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_rf_regr.p\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(selected_params_rf_regr, open(path, \"wb\"))\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_rf_regr.csv\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "df_predicted_rf_regr.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_search_space = [\n",
    "    {\n",
    "        \"estimator__learning_rate\": [0.1, 0.5, 1],\n",
    "        \"estimator__gamma\": [0.1, 0.5, 2],\n",
    "        \"estimator__max_depth\": [6, 8],\n",
    "        \"estimator__reg_lambda\": [0.001, 0.1, 1],\n",
    "        \"estimator__n_estimators\": [100, 200],\n",
    "        \"estimator__colsample_bytree\": [0.5, 0.7],\n",
    "    }\n",
    "]\n",
    "\n",
    "selected_features_xgb_regr, selected_params_xgb_regr_full = xgb_regression_features(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    features=features,\n",
    "    search_space=xgb_search_space,\n",
    "    min_features_to_select=1,\n",
    "    cv_splits=5,\n",
    "    GS_score=\"neg_root_mean_squared_error\",\n",
    "    objective='\"reg:squarederror\"',\n",
    "    GS_randomized=True,\n",
    "    GS_n_iter=50,\n",
    "    verbose=10,\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Number of selected features XGBoost Regression {len(selected_features_xgb_regr)}\")\n",
    "print(f\"Selected features XGBoost Regression: {selected_features_xgb_regr}\")\n",
    "print(f\"Selected Parameters XGBoost Regression: {selected_params_xgb_regr_full}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the performance estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the selected features for XGB\n",
    "selected_features_xgb_regr = [\n",
    "    'rice_area', \n",
    "    'mean_slope', \n",
    "    'mean_elevation_m', \n",
    "    'ruggedness_stdev', \n",
    "    'mean_ruggedness', \n",
    "    'slope_stdev', \n",
    "    'area_km2', \n",
    "    'poverty_perc', \n",
    "    'with_coast', \n",
    "    'coast_length', \n",
    "    'perimeter', \n",
    "    'glat', \n",
    "    'glon', \n",
    "    'coast_peri_ratio', \n",
    "    'rainfall_sum', \n",
    "    'rainfall_max', \n",
    "    'dis_track_min', \n",
    "    'vmax_sust'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_search_space = [\n",
    "    {\n",
    "        \"xgb__learning_rate\": [0.1, 0.5, 1],\n",
    "        \"xgb__gamma\": [0.1, 0.5, 2],\n",
    "        \"xgb__max_depth\": [6, 8],\n",
    "        \"xgb__reg_lambda\": [0.001, 0.1, 1],\n",
    "        \"xgb__n_estimators\": [100, 200],\n",
    "        \"xgb__colsample_bytree\": [0.5, 0.7],\n",
    "    }\n",
    "]\n",
    "\n",
    "df_predicted_xgb_regr, selected_params_xgb_regr = xgb_regression_performance(\n",
    "    df_train_list=df_train_list,\n",
    "    df_test_list=df_test_list,\n",
    "    features=selected_features_xgb_regr,\n",
    "    search_space=xgb_search_space,\n",
    "    cv_splits=5,\n",
    "    objective=\"reg:squarederror\",\n",
    "    GS_score=\"neg_root_mean_squared_error\",\n",
    "    GS_randomized=True,\n",
    "    GS_n_iter=50,\n",
    "    verbose=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\selected_params_xgb_regr.p\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(selected_params_xgb_regr, open(path, \"wb\"))\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\output\\\\02\\\\df_predicted_xgb_regr.csv\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "df_predicted_xgb_regr.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the average\n",
    "df_predicted_mean = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\n",
    "\n",
    "for i in range(len(df_train_list)):\n",
    "\n",
    "    train = df_train_list[i]\n",
    "    test = df_test_list[i]\n",
    "\n",
    "    y_train = train[\"perc_loss\"]\n",
    "    y_test = test[\"perc_loss\"]\n",
    "\n",
    "    y_test_pred = [np.mean(y_train)] * len(y_test)\n",
    "\n",
    "    df_predicted_temp = pd.DataFrame(\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_test_pred}\n",
    "    )\n",
    "\n",
    "    df_predicted_mean = pd.concat([df_predicted_mean, df_predicted_temp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simle Linear Regression with Wind Speed\n",
    "input_variable = \"vmax\"\n",
    "df_predicted_lr = pd.DataFrame(columns=[\"year\", \"actual\", \"predicted\"])\n",
    "\n",
    "for i in range(len(df_train_list)):\n",
    "\n",
    "    train = df_train_list[i]\n",
    "    test = df_test_list[i]\n",
    "\n",
    "    x_train = train[input_variable].values.reshape(-1, 1)\n",
    "    y_train = train[\"perc_loss\"].values.reshape(-1, 1)\n",
    "\n",
    "    x_test = test[input_variable].values.reshape(-1, 1)\n",
    "    y_test = test[\"perc_loss\"]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    lr_fitted = model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_train = lr_fitted.predict(x_train)\n",
    "    y_pred_test = lr_fitted.predict(x_test)\n",
    "    y_pred_test = y_pred_test.tolist()\n",
    "    y_pred_test = [val for sublist in y_pred_test for val in sublist]\n",
    "\n",
    "    df_predicted_temp = pd.DataFrame(\n",
    "        {\"year\": test[\"year\"], \"actual\": y_test, \"predicted\": y_pred_test}\n",
    "    )\n",
    "\n",
    "    df_predicted_lr = pd.concat([df_predicted_lr, df_predicted_temp])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.281097</td>\n",
       "      <td>0.334649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.318810</td>\n",
       "      <td>0.354945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>0.292208</td>\n",
       "      <td>0.333280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Models       MAE      RMSE\n",
       "0             Random Forest  0.281097  0.334649\n",
       "1                   Average  0.318810  0.354945\n",
       "2  Simple Linear Regression  0.292208  0.333280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest\": df_predicted_rf_regr,\n",
    "    # \"XGBoost\": df_predicted_xgb_regr,\n",
    "    \"Average\": df_predicted_mean,\n",
    "    \"Simple Linear Regression\": df_predicted_lr,\n",
    "}\n",
    "\n",
    "mae = []\n",
    "rmse = []\n",
    "\n",
    "# add 'list' if error\n",
    "for df_temp in models.values():\n",
    "    mae.append(mean_absolute_error(df_temp[\"actual\"], df_temp[\"predicted\"]))\n",
    "    rmse.append(mean_squared_error(df_temp[\"actual\"], df_temp[\"predicted\"], squared=False))\n",
    "\n",
    "df_results_regr = pd.DataFrame({\"Models\": list(models.keys()), \"MAE\": mae, \"RMSE\": rmse})\n",
    "\n",
    "display(df_results_regr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:27: ResourceWarning: unclosed file <_io.BufferedWriter name='C:\\\\Users\\\\Marieke\\\\GitHub\\\\Typhoon_IBF_Rice_Damage_Model\\\\IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_regr_rf.sav'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    max_depth=20, min_samples_leaf=1, min_samples_split=8, n_estimators=100,\n",
    ")\n",
    "\n",
    "selected_features_rf_regr = [\n",
    "    \"mean_slope\",\n",
    "    \"mean_elevation_m\",\n",
    "    \"ruggedness_stdev\",\n",
    "    \"mean_ruggedness\",\n",
    "    \"area_km2\",\n",
    "    \"poverty_perc\",\n",
    "    \"coast_length\",\n",
    "    \"perimeter\",\n",
    "    \"glat\",\n",
    "    \"glon\",\n",
    "    \"coast_peri_ratio\",\n",
    "    \"rainfall_max_6h\",\n",
    "    \"rainfall_max_24h\",\n",
    "    \"dis_track_min\",\n",
    "    \"vmax\",\n",
    "]\n",
    "\n",
    "rf_fitted = rf.fit(X[selected_features_rf_regr], y)\n",
    "\n",
    "file_name = \"IBF_typhoon_model\\\\models\\\\saved_models\\\\trained_regr_rf.sav\"\n",
    "path = os.path.join(cdir, file_name)\n",
    "pickle.dump(rf_fitted, open(path, \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b367308e6f055391f859b515bbb645f6640c7b29224a7a1d3f6b55de7d9ef17f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
